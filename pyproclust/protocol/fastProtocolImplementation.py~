'''
Created on 06/08/2012

@author: victor
'''
import pyproclust.tools.commonTools as common
import pyproclust.tools.scriptTools as scripts_common
from pyproclust.protocol.protocolImplementation import Protocol, spawn_gromos,\
    spawn_hierarchical, spawn_dbscan, spawn_kmedoids, spawn_random
from pyproclust.protocol.processPool import ProcessPool
from pyproclust.tools.distanceMatrixAnalysisTools import statistical_analysis
from pyproclust.clustering.comparison.comparator import Comparator
import pyRMSD.RMSD
import pyRMSD.utils
from pyproclust.matrix.condensedMatrix import CondensedDistanceMatrix
from pyRMSD.condensedMatrix import CondensedMatrix
import time

class fastProtocol(Protocol):

    def __init__(self):
        pass
    
    def run(self,protocol_params):
        global_time_start = time.time()
        self.condensed_distance_matrix = None
        time_file = open("timing.txt","w")
        
        #####################
        # Create subdirectories 
        #####################
        common.print_and_flush( "Creating workspace.\n")
        self.create_workspace(protocol_params)
        
        ######################
        # Obtaining the distance matrix
        ######################
        time_start = time.time()
        if protocol_params.shallWeCalculateDistanceMatrix():
            common.print_and_flush( "We are going to calculate the distance matrix.\n")
            self.genMatrix(protocol_params)
            time_end = time.time()
            time_file.write( 'Creating the matrix took %0.3fs\n' % (time_end-time_start))
        else:
            common.print_and_flush( "We don't need to calculate the distance matrix because it is provided in:" + protocol_params.matrix_path)
            self.loadMatrix(protocol_params)
            time_end = time.time()
            time_file.write( 'Loading the matrix took %0.3fs\n' % (time_end-time_start))
        time_file,flush()

        ######################
        # Matrix analysis
        ######################
        time_start = time.time()
        common.print_and_flush("Getting max and mean of matrix.\n")
        min_dist, max_dist, mean_dist = statistical_analysis(None,self.condensed_distance_matrix) #@UnusedVariable
	print "Min dist: ",min_dist
        print "Max dist: ",max_dist
        print "Mean dist: ",mean_dist
        time_end = time.time()
        time_file.write( 'Short matrix analysis took %0.3fs\n' % (time_end-time_start))
	time_file,flush()
                
        ######################
        # Clustering exploration
        ######################
        time_start = time.time()
        self.do_clustering_exploration(protocol_params, self.fast_condensed_distance_matrix, max_dist, mean_dist)
        time_end = time.time()
        time_file.write( 'Clustering generation took %0.3fs\n' % (time_end-time_start))
	time_file,flush()
                
        ######################
        # Load created clusterings from disk
        ######################
        time_start = time.time()
        non_filtered_clusterings = scripts_common.load_binary_clusters("clusterings/")
        time_end = time.time()
        time_file.write( 'Clustering loading took %0.3fs\n' % (time_end-time_start))
	time_file,flush()

        ######################
        # First filtering
        ######################
        time_start = time.time()
        self.do_clustering_filtering(protocol_params,non_filtered_clusterings)
        time_file.write( 'Filtering took %0.3fs\n' % (time_end-time_start))
	time_file,flush()

        if len(self.clusterings) == 0:
            common.print_and_flush( "The clustering search gave no clusterings. Relax noise or num. of clusters parameters.")
            common.print_and_flush( "Exiting...\n")
        
        else:      
            ######################
            # Clustering scoring
            ######################
            time_start = time.time()
            string_results, results_pack = self.clustering_scoring(protocol_params)
            time_end = time.time()
            time_file.write( 'Clustering scoring took %0.3fs\n' % (time_end-time_start))
            time_file,flush()

                    
            ######################
            # Bake up results
            ######################
            self.save_results(protocol_params,string_results,results_pack)
            
            ######################
            # Choose the best one
            ######################
            best_score, best_clustering = protocol_params.chooseBestClustering(results_pack)
            best_cluster_string = "Best clustering has a normalized score of : %.4f Details: %s\n"%(best_score,best_clustering.details)
            common.print_and_flush(  best_cluster_string)
            
            if protocol_params.most_representative_pdb_file != "":
                self.save_most_representative(protocol_params,best_clustering)
            
            if protocol_params.shallWeCompareTrajectories():
                comparator = Comparator()
                comparator.run(best_clustering,protocol_params.pdb1,protocol_params.pdb2,self.condensed_distance_matrix,"results/"+protocol_params.state_graph_path)
                common.print_and_flush( comparator.result_string+"\n") 
                if protocol_params.comparator_results_path != "":
                    file_handler = open("results/"+protocol_params.comparator_results_path,"w")
                    file_handler.write(best_cluster_string )
                    file_handler.write(comparator.result_string )
                    file_handler.close()
        global_time_end = time.time()
        time_file.write( 'Clustering scoring took %0.3fs\n' % (global_time_end-global_time_start))
        time_file.close()
    
    def matrix_creation(self, protocol_params, matrix_prefix, trajectory_path):
        coordsets,number_of_conformations,number_of_atoms = pyRMSD.utils.getCoorsetsFromPDB(trajectory_path) #@UnusedVariable
        rmsd = pyRMSD.RMSD.calculateRMSDCondensedMatrix(coordsets, "OMP_CALCULATOR")
        self.condensed_distance_matrix = CondensedDistanceMatrix(rmsd)
        self.fast_condensed_distance_matrix = CondensedMatrix(rmsd)
    
    def loadMatrix(self,protocol_params):
        common.print_and_flush("Loading condensed matrix...")
        self.condensed_distance_matrix = scripts_common.load_matrix(protocol_params.matrix_path)
        self.fast_condensed_distance_matrix = CondensedMatrix(self.condensed_distance_matrix.get_data())
        common.print_and_flush(" Done\n")
        
