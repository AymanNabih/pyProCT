<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>pyproct_doxy: /home/victor/workspaces/Python/pyProClust/pyproct/clustering/comparison/distrprob/kullbackLieblerDivergence.py Source File</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">pyproct_doxy
   
   </div>
   
  </td>
  
  
  
   
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
   
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('kullbackLieblerDivergence_8py.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">kullbackLieblerDivergence.py</div>  </div>
</div><!--header-->
<div class="contents">
<a href="kullbackLieblerDivergence_8py.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a><a class="code" href="namespacepyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence.html">00001</a> <span class="comment">##</span>
<a name="l00002"></a>00002 <span class="comment"># </span>
<a name="l00003"></a>00003 <span class="comment"># Created on 20/08/2012</span>
<a name="l00004"></a>00004 <span class="comment"># </span>
<a name="l00005"></a>00005 <span class="comment"># @author: victor</span>
<a name="l00006"></a>00006 <span class="comment"># </span>
<a name="l00007"></a>00007 <span class="keyword">import</span> numpy
<a name="l00008"></a>00008 <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt
<a name="l00009"></a>00009 <span class="keyword">import</span> math
<a name="l00010"></a>00010 <span class="keyword">import</span> json
<a name="l00011"></a>00011 <span class="keyword">import</span> os.path
<a name="l00012"></a>00012 
<a name="l00013"></a>00013 <span class="comment">##</span>
<a name="l00014"></a>00014 <span class="comment"># </span>
<a name="l00015"></a>00015 <span class="comment">#     Applies a smoothing process to the distribution.</span>
<a name="l00016"></a>00016 <span class="comment">#     See http://mathoverflow.net/questions/72668/how-to-compute-kl-divergence-when-pmf-contains-0s</span>
<a name="l00017"></a>00017 <span class="comment">#     for an explanation about the problem and the solution.</span>
<a name="l00018"></a>00018 <span class="comment">#     </span>
<a name="l00019"></a>00019 <span class="comment">#     @param distribution: distribution to be smoothed</span>
<a name="l00020"></a>00020 <span class="comment">#     @param small_value: value to be set to those bins with 0 probability</span>
<a name="l00021"></a>00021 <span class="comment">#     </span>
<a name="l00022"></a>00022 <span class="comment">#     @return: The smoothed distribution.</span>
<a name="l00023"></a>00023 <span class="comment">#     </span>
<a name="l00024"></a><a class="code" href="namespacepyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence.html#a69996c34fecccd4354dbe6ff8f258d1e">00024</a> <span class="keyword">def </span><a class="code" href="namespacepyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence.html#a69996c34fecccd4354dbe6ff8f258d1e" title="Applies a smoothing process to the distribution.">smoothed</a>(distribution,small_value = 1.0e-8):
<a name="l00025"></a>00025     total_number_of_samples = len(distribution)
<a name="l00026"></a>00026     samples_in_distrib = numpy.count_nonzero(distribution)
<a name="l00027"></a>00027     pc = small_value * (total_number_of_samples - samples_in_distrib) / samples_in_distrib
<a name="l00028"></a>00028     smoothed_distrib = numpy.empty(len(distribution))
<a name="l00029"></a>00029     <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(distribution)):
<a name="l00030"></a>00030         <span class="keywordflow">if</span> distribution[i] == 0:
<a name="l00031"></a>00031             smoothed_distrib[i] = small_value
<a name="l00032"></a>00032         <span class="keywordflow">else</span>:
<a name="l00033"></a>00033             smoothed_distrib[i] = distribution[i] - pc
<a name="l00034"></a>00034     <span class="keywordflow">return</span> smoothed_distrib
<a name="l00035"></a>00035 
<a name="l00036"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html">00036</a> <span class="keyword">class </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html">KullbackLeiblerDivergence</a>(<a class="code" href="classobject.html">object</a>):
<a name="l00037"></a>00037     
<a name="l00038"></a>00038     <span class="comment"># Number of bins that the histogram will have when calculating the</span>
<a name="l00039"></a>00039     <span class="comment"># distribution</span>
<a name="l00040"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aaae4a7dce905aff0227081ffa6196661">00040</a>     NUM_BINS = 200
<a name="l00041"></a>00041     
<a name="l00042"></a>00042     <span class="comment">##</span>
<a name="l00043"></a>00043     <span class="comment"># </span>
<a name="l00044"></a>00044     <span class="comment">#         Class constructor. Does the actual calculation.</span>
<a name="l00045"></a>00045     <span class="comment">#         </span>
<a name="l00046"></a>00046     <span class="comment">#         @param pdb_info: An structure containing paths and other useful data about the pdbs being used.</span>
<a name="l00047"></a>00047     <span class="comment">#         @param condensedMatrix: The actual calculated matrix.</span>
<a name="l00048"></a>00048     <span class="comment">#         </span>
<a name="l00049"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">00049</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a4915893e9eded0c42e460ea89cfd6a93" title="Class constructor.">__init__</a>(self, pdb_info, condensedMatrix):
<a name="l00050"></a>00050         self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a> = pdb_info
<a name="l00051"></a>00051         
<a name="l00052"></a>00052         <span class="comment"># Getting submatrices.</span>
<a name="l00053"></a>00053         submatrices = {}
<a name="l00054"></a>00054         next_first_element = 0
<a name="l00055"></a>00055         <span class="keywordflow">for</span> pdb <span class="keywordflow">in</span> pdb_info:
<a name="l00056"></a>00056             submatrices[pdb[<span class="stringliteral">&quot;source&quot;</span>]] = KullbackLeiblerDivergence.get_matrix_data(condensedMatrix, next_first_element, pdb[<span class="stringliteral">&quot;conformations&quot;</span>])
<a name="l00057"></a>00057             next_first_element += pdb[<span class="stringliteral">&quot;conformations&quot;</span>]
<a name="l00058"></a>00058         
<a name="l00059"></a>00059         <span class="comment"># Getting max and min values</span>
<a name="l00060"></a>00060         max_vals = []
<a name="l00061"></a>00061         min_vals = []
<a name="l00062"></a>00062         <span class="keywordflow">for</span> pdb <span class="keywordflow">in</span> pdb_info:
<a name="l00063"></a>00063             max_vals.append(numpy.max(submatrices[pdb[<span class="stringliteral">&quot;source&quot;</span>]]))
<a name="l00064"></a>00064             min_vals.append(numpy.min(submatrices[pdb[<span class="stringliteral">&quot;source&quot;</span>]]))
<a name="l00065"></a>00065         
<a name="l00066"></a>00066         distribution_range = (numpy.min(min_vals), numpy.max(max_vals))
<a name="l00067"></a>00067         
<a name="l00068"></a>00068         <span class="comment"># Generate histograms</span>
<a name="l00069"></a>00069         self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a> = {}
<a name="l00070"></a>00070         <span class="keywordflow">for</span> pdb <span class="keywordflow">in</span> pdb_info:
<a name="l00071"></a>00071             prob_histogram, bins =  KullbackLeiblerDivergence.get_probability_histogram(submatrices[pdb[<span class="stringliteral">&quot;source&quot;</span>]],
<a name="l00072"></a>00072                                                                                    distribution_range,
<a name="l00073"></a>00073                                                                                    KullbackLeiblerDivergence.NUM_BINS)
<a name="l00074"></a>00074             self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb[<span class="stringliteral">&quot;source&quot;</span>]] =(<a class="code" href="namespacepyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence.html#a69996c34fecccd4354dbe6ff8f258d1e" title="Applies a smoothing process to the distribution.">smoothed</a>(prob_histogram), bins)
<a name="l00075"></a>00075         
<a name="l00076"></a>00076         <span class="comment"># Calculate KL values</span>
<a name="l00077"></a>00077         self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aa0cee59496d2827155fce009800a32af">KL_matrix</a> = numpy.zeros((len(pdb_info),len(pdb_info)))
<a name="l00078"></a>00078         <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(pdb_info)-1):
<a name="l00079"></a>00079             <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(i+1,len(pdb_info)):
<a name="l00080"></a>00080                 self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aa0cee59496d2827155fce009800a32af">KL_matrix</a>[i][j] = KullbackLeiblerDivergence.kullback_leibler_divergence_calculation(self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb_info[i][<span class="stringliteral">&quot;source&quot;</span>]][0],
<a name="l00081"></a>00081                                                                                        self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb_info[j][<span class="stringliteral">&quot;source&quot;</span>]][0])
<a name="l00082"></a>00082                 self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aa0cee59496d2827155fce009800a32af">KL_matrix</a>[j][i] = KullbackLeiblerDivergence.kullback_leibler_divergence_calculation(self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb_info[j][<span class="stringliteral">&quot;source&quot;</span>]][0],
<a name="l00083"></a>00083                                                                                        self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb_info[i][<span class="stringliteral">&quot;source&quot;</span>]][0])
<a name="l00084"></a>00084         
<a name="l00085"></a>00085 <span class="comment">#         self.pdb1 = pdb_info[0][&quot;source&quot;]</span>
<a name="l00086"></a>00086 <span class="comment">#         self.pdb2 = pdb_info[1][&quot;source&quot;]</span>
<a name="l00087"></a>00087 <span class="comment">#         number_of_models_1 = pdb_info[0][&quot;conformations&quot;]</span>
<a name="l00088"></a>00088 <span class="comment">#         number_of_models_2 = pdb_info[1][&quot;conformations&quot;]</span>
<a name="l00089"></a>00089 <span class="comment">#         </span>
<a name="l00090"></a>00090 <span class="comment">#         first_pdb_submatrix = KullbackLeiblerDivergence.get_matrix_data(condensedMatrix,0,number_of_models_1)</span>
<a name="l00091"></a>00091 <span class="comment">#         second_pdb_submatrix = KullbackLeiblerDivergence.get_matrix_data(condensedMatrix, number_of_models_1, number_of_models_2)</span>
<a name="l00092"></a>00092 <span class="comment">#         </span>
<a name="l00093"></a>00093 <span class="comment">#         max_of_submatrices = max(numpy.max(first_pdb_submatrix),numpy.max(second_pdb_submatrix))</span>
<a name="l00094"></a>00094 <span class="comment">#         min_of_submatrices = min(numpy.min(first_pdb_submatrix),numpy.min(second_pdb_submatrix))</span>
<a name="l00095"></a>00095 <span class="comment">#         distribution_range = (min_of_submatrices, max_of_submatrices)</span>
<a name="l00096"></a>00096 <span class="comment">#         </span>
<a name="l00097"></a>00097 <span class="comment">#         prob_histogram1, self.bins1 = KullbackLeiblerDivergence.get_probability_histogram(first_pdb_submatrix,</span>
<a name="l00098"></a>00098 <span class="comment">#                                                                                           distribution_range,</span>
<a name="l00099"></a>00099 <span class="comment">#                                                                                           KullbackLeiblerDivergence.NUM_BINS)</span>
<a name="l00100"></a>00100 <span class="comment">#         </span>
<a name="l00101"></a>00101 <span class="comment">#         prob_histogram2, self.bins2 = KullbackLeiblerDivergence.get_probability_histogram(second_pdb_submatrix,</span>
<a name="l00102"></a>00102 <span class="comment">#                                                                                           distribution_range,</span>
<a name="l00103"></a>00103 <span class="comment">#                                                                                           KullbackLeiblerDivergence.NUM_BINS)</span>
<a name="l00104"></a>00104 <span class="comment"># </span>
<a name="l00105"></a>00105 <span class="comment">#         self.smoothed_prob_histogram1 = smoothed(prob_histogram1)</span>
<a name="l00106"></a>00106 <span class="comment">#         self.smoothed_prob_histogram2 = smoothed(prob_histogram2)</span>
<a name="l00107"></a>00107 <span class="comment">#         </span>
<a name="l00108"></a>00108 <span class="comment">#         self.kl1 = KullbackLeiblerDivergence.kullback_leibler_divergence_calculation(self.smoothed_prob_histogram1,self.smoothed_prob_histogram2)</span>
<a name="l00109"></a>00109 <span class="comment">#         self.kl2 = KullbackLeiblerDivergence.kullback_leibler_divergence_calculation(self.smoothed_prob_histogram2,self.smoothed_prob_histogram1)</span>
<a name="l00110"></a>00110 <span class="comment">#     </span>
<a name="l00111"></a>00111     <span class="comment">##</span>
<a name="l00112"></a>00112     <span class="comment"># </span>
<a name="l00113"></a>00113     <span class="comment">#         Saves a plot of the distributions and the actual values of them.</span>
<a name="l00114"></a>00114     <span class="comment">#         @param where: The name of the file without extension (&quot;.png&quot; will be appended to the final name). </span>
<a name="l00115"></a>00115     <span class="comment">#         </span>
<a name="l00116"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a90072a925f734f62f2419f3e79149363">00116</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a90072a925f734f62f2419f3e79149363" title="Saves a plot of the distributions and the actual values of them.">save</a>(self, where):
<a name="l00117"></a>00117         image_path = self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ae8be324c5ee88d06ceed803e185f00e9" title="Saves a plot of the distributions.">plot_distributions</a>(where)
<a name="l00118"></a>00118         <span class="keywordflow">return</span> self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a6674d4c5574a4c9369a7550180f5cd14" title="Saves the K-L values in a text file containing its json representation.">to_json</a>(where, image_path)
<a name="l00119"></a>00119         
<a name="l00120"></a>00120     <span class="comment">##</span>
<a name="l00121"></a>00121     <span class="comment"># </span>
<a name="l00122"></a>00122     <span class="comment">#         Saves a plot of the distributions.</span>
<a name="l00123"></a>00123     <span class="comment">#         @param where: The name of the file without extension (&quot;.png&quot; will be appended to the final name). </span>
<a name="l00124"></a>00124     <span class="comment">#         </span>
<a name="l00125"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ae8be324c5ee88d06ceed803e185f00e9">00125</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ae8be324c5ee88d06ceed803e185f00e9" title="Saves a plot of the distributions.">plot_distributions</a>(self, where):
<a name="l00126"></a>00126 <span class="comment">#         fig = plt.figure()</span>
<a name="l00127"></a>00127 <span class="comment">#         ax = fig.add_subplot(111)</span>
<a name="l00128"></a>00128 <span class="comment">#         ax.plot(self.bins1[:self.NUM_BINS],self.smoothed_prob_histogram1, &#39;b--&#39;, linewidth=2)</span>
<a name="l00129"></a>00129 <span class="comment">#         ax.plot(self.bins2[:self.NUM_BINS],self.smoothed_prob_histogram2, &#39;r--&#39;, linewidth=2)</span>
<a name="l00130"></a>00130 <span class="comment">#         ax.grid(True)</span>
<a name="l00131"></a>00131 <span class="comment">#         ax.legend([plt.Rectangle((0, 0), 1, 1, fc=&quot;b&quot;),plt.Rectangle((0, 0), 1, 1, fc=&quot;r&quot;)],[self.pdb1,self.pdb2])</span>
<a name="l00132"></a>00132 <span class="comment">#         plt.savefig(where+&quot;.png&quot;)</span>
<a name="l00133"></a>00133         fig = plt.figure()
<a name="l00134"></a>00134         ax = fig.add_subplot(111)
<a name="l00135"></a>00135         <span class="keywordflow">for</span> pdb <span class="keywordflow">in</span> self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>:
<a name="l00136"></a>00136             smoothed_his, bins  =  self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac9fa49a596186ba078ddb200e69d23e1">histograms</a>[pdb[<span class="stringliteral">&quot;source&quot;</span>]] 
<a name="l00137"></a>00137             ax.plot(bins[:self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aaae4a7dce905aff0227081ffa6196661">NUM_BINS</a>],smoothed_his, linewidth = 2, label= os.path.basename(pdb[<span class="stringliteral">&quot;source&quot;</span>]))
<a name="l00138"></a>00138 
<a name="l00139"></a>00139         ax.grid(<span class="keyword">True</span>)
<a name="l00140"></a>00140 <span class="comment">#         ax.legend([plt.Rectangle((0, 0), 1, 1, fc=&quot;b&quot;),plt.Rectangle((0, 0), 1, 1, fc=&quot;r&quot;)],[self.pdb1,self.pdb2])</span>
<a name="l00141"></a>00141         plt.legend(prop={<span class="stringliteral">&#39;size&#39;</span>:6})
<a name="l00142"></a>00142         plt.savefig(where+<span class="stringliteral">&quot;.png&quot;</span>)
<a name="l00143"></a>00143  
<a name="l00144"></a>00144         <span class="keywordflow">return</span> where+<span class="stringliteral">&quot;.png&quot;</span>
<a name="l00145"></a>00145     
<a name="l00146"></a>00146     <span class="comment">##</span>
<a name="l00147"></a>00147     <span class="comment"># </span>
<a name="l00148"></a>00148     <span class="comment">#         Saves the K-L values in a text file containing its json representation.</span>
<a name="l00149"></a>00149     <span class="comment">#         @param where: The name of the file without extension (&quot;.json&quot; will be appended to the final name).</span>
<a name="l00150"></a>00150     <span class="comment">#         @param image_path: Place where we have saved the image with the distribution. </span>
<a name="l00151"></a>00151     <span class="comment">#         </span>
<a name="l00152"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a6674d4c5574a4c9369a7550180f5cd14">00152</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a6674d4c5574a4c9369a7550180f5cd14" title="Saves the K-L values in a text file containing its json representation.">to_json</a>(self, where, image_path):
<a name="l00153"></a>00153 <span class="comment">#         pre_json_dic = {&quot;kl1&quot;:self.kl1,&quot;kl2&quot;:self.kl2,&quot;image&quot;:image_path}</span>
<a name="l00154"></a>00154 <span class="comment">#         for pdb in self.pdb_info:</span>
<a name="l00155"></a>00155 <span class="comment">#         open( where+&quot;.json&quot;,&quot;w&quot;).write(json.dumps({&quot;kl1&quot;:self.kl1,&quot;kl2&quot;:self.kl2,&quot;image&quot;:image_path}, indent=4, separators=(&#39;,&#39;, &#39;: &#39;)))</span>
<a name="l00156"></a>00156 <span class="comment">#         return pre_json_dic</span>
<a name="l00157"></a>00157         pre_json = []
<a name="l00158"></a>00158         <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>)-1):
<a name="l00159"></a>00159             <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(i+1,len(self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>)):
<a name="l00160"></a>00160                 pre_json.append({
<a name="l00161"></a>00161                                  <span class="stringliteral">&quot;A&quot;</span>:self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>[i],
<a name="l00162"></a>00162                                  <span class="stringliteral">&quot;B&quot;</span>:self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>[j],
<a name="l00163"></a>00163                                  <span class="stringliteral">&quot;KL&quot;</span>: self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aa0cee59496d2827155fce009800a32af">KL_matrix</a>[i][j] 
<a name="l00164"></a>00164                                  })
<a name="l00165"></a>00165                 pre_json.append({
<a name="l00166"></a>00166                                  <span class="stringliteral">&quot;A&quot;</span>:self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>[j],
<a name="l00167"></a>00167                                  <span class="stringliteral">&quot;B&quot;</span>:self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ab4ca83a34afdf54ebabad85555ed16cf">pdb_info</a>[i],
<a name="l00168"></a>00168                                  <span class="stringliteral">&quot;KL&quot;</span>: self.<a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#aa0cee59496d2827155fce009800a32af">KL_matrix</a>[j][i] 
<a name="l00169"></a>00169                                  })
<a name="l00170"></a>00170                 
<a name="l00171"></a>00171         open( where+<span class="stringliteral">&quot;.json&quot;</span>,<span class="stringliteral">&quot;w&quot;</span>).write(json.dumps(pre_json, indent=4, separators=(<span class="stringliteral">&#39;,&#39;</span>, <span class="stringliteral">&#39;: &#39;</span>)))
<a name="l00172"></a>00172     
<a name="l00173"></a>00173     @classmethod
<a name="l00174"></a>00174     <span class="comment">##</span>
<a name="l00175"></a>00175     <span class="comment"># </span>
<a name="l00176"></a>00176     <span class="comment">#         Creates the histogram using numpy.</span>
<a name="l00177"></a>00177     <span class="comment">#         @param data: data from which we will create the histogram (in this case the data of one of the submatrices)</span>
<a name="l00178"></a>00178     <span class="comment">#         @param bin_range: tuple with the maximum and minimum value the sum of all distributions (not only this one) can have.</span>
<a name="l00179"></a>00179     <span class="comment">#         @param num_bins: Number of discrete parts of the distribution.</span>
<a name="l00180"></a>00180     <span class="comment">#         </span>
<a name="l00181"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac25e1fe94353b4a0bc5a110109ea0ea9">00181</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac25e1fe94353b4a0bc5a110109ea0ea9" title="Creates the histogram using numpy.">get_probability_histogram</a>(cls,data,bin_range,num_bins):
<a name="l00182"></a>00182         hist = numpy.histogram(data, num_bins, bin_range)
<a name="l00183"></a>00183         float_hist = numpy.asarray(hist[0],dtype=numpy.float32)
<a name="l00184"></a>00184         <span class="keywordflow">return</span> float_hist/len(data), hist[1]
<a name="l00185"></a>00185     
<a name="l00186"></a>00186     @classmethod
<a name="l00187"></a>00187     <span class="comment">##</span>
<a name="l00188"></a>00188     <span class="comment"># </span>
<a name="l00189"></a>00189     <span class="comment">#         A matrix generated from the concatenation of two pdbs may have 3 submatrices. First is the pairwise matrix of </span>
<a name="l00190"></a>00190     <span class="comment">#         the first pdb, second the pairwise matrix of the second, and third is the distance matrix of pdb1 vs pdb2 </span>
<a name="l00191"></a>00191     <span class="comment">#         (in which info is duplicated, as its itself a pairwise distance matrix). This function grabs the data </span>
<a name="l00192"></a>00192     <span class="comment">#         of one of the two first submatrices.</span>
<a name="l00193"></a>00193     <span class="comment">#         </span>
<a name="l00194"></a>00194     <span class="comment">#         @param matrix: The matrix we are talking about :/</span>
<a name="l00195"></a>00195     <span class="comment">#         @param initial_element: is the index of the initial element of the pdb we want to extract the data. For instance</span>
<a name="l00196"></a>00196     <span class="comment">#         if we are working with 2 trajectories of 3 and 4 frames, indexes are [tr1:[0,1,2] tr2:[3,4,5,6]], so to extract </span>
<a name="l00197"></a>00197     <span class="comment">#         the first submatrix data, initial_element would be 0 and number_of_elements 3. Extracting the second submatrix will</span>
<a name="l00198"></a>00198     <span class="comment">#         need a initial_element value of 3 and a number_of_elements value of 4.</span>
<a name="l00199"></a>00199     <span class="comment">#         @param number_of_elements: As explained above, the number of models the pdb we are working with has.</span>
<a name="l00200"></a>00200     <span class="comment">#         </span>
<a name="l00201"></a>00201     <span class="comment">#         @return: A 1D numpy.array containing the submatrix data. </span>
<a name="l00202"></a>00202     <span class="comment">#         </span>
<a name="l00203"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac20b1aa3af4e455db402c67a68538c70">00203</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ac20b1aa3af4e455db402c67a68538c70" title="A matrix generated from the concatenation of two pdbs may have 3 submatrices.">get_matrix_data</a>(cls,matrix,initial_element,number_of_elements):
<a name="l00204"></a>00204         traj_data = numpy.empty(number_of_elements*(number_of_elements-1)/2)
<a name="l00205"></a>00205         final_element = initial_element+number_of_elements
<a name="l00206"></a>00206         m_i = 0
<a name="l00207"></a>00207         <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(initial_element, final_element):
<a name="l00208"></a>00208             <span class="keywordflow">for</span> j <span class="keywordflow">in</span> range(i, final_element):
<a name="l00209"></a>00209                 if(i!=j):
<a name="l00210"></a>00210                     traj_data[m_i] = matrix[i,j]
<a name="l00211"></a>00211                     m_i = m_i+1
<a name="l00212"></a>00212         <span class="keywordflow">return</span> traj_data
<a name="l00213"></a>00213     
<a name="l00214"></a>00214     @classmethod
<a name="l00215"></a>00215     <span class="comment">##</span>
<a name="l00216"></a>00216     <span class="comment"># </span>
<a name="l00217"></a>00217     <span class="comment">#         Calculates the Kullback - Leibler divergence of two distributions.</span>
<a name="l00218"></a>00218     <span class="comment">#         @param dist1: first distribution</span>
<a name="l00219"></a>00219     <span class="comment">#         @param dist2: second distribution</span>
<a name="l00220"></a>00220     <span class="comment">#         </span>
<a name="l00221"></a>00221     <span class="comment">#         @return: The Kullback-Leibler Divergence value</span>
<a name="l00222"></a>00222     <span class="comment">#         </span>
<a name="l00223"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a03c44c555f71ec560a5079a786911426">00223</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#a03c44c555f71ec560a5079a786911426" title="Calculates the Kullback - Leibler divergence of two distributions.">kullback_leibler_divergence_calculation</a>(cls, dist1, dist2):
<a name="l00224"></a>00224         kl = 0;
<a name="l00225"></a>00225         <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(dist1)):
<a name="l00226"></a>00226             <span class="keywordflow">try</span>:
<a name="l00227"></a>00227                 kl += dist1[i] * math.log(dist1[i]/dist2[i],2)
<a name="l00228"></a>00228             <span class="keywordflow">except</span> ArithmeticError:
<a name="l00229"></a>00229                 <span class="keywordflow">print</span> <span class="stringliteral">&quot;dist1[i]&quot;</span>, dist1[i],<span class="stringliteral">&quot;dist2[i]&quot;</span>, dist2[i]
<a name="l00230"></a>00230         <span class="keywordflow">return</span> kl
<a name="l00231"></a>00231     
<a name="l00232"></a>00232     <span class="comment">##</span>
<a name="l00233"></a>00233     <span class="comment"># </span>
<a name="l00234"></a>00234     <span class="comment">#         A simple getter...</span>
<a name="l00235"></a>00235     <span class="comment">#         </span>
<a name="l00236"></a><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ad35ddee427d0c39d2d50753e39a7c0e6">00236</a>     <span class="keyword">def </span><a class="code" href="classpyproct_1_1clustering_1_1comparison_1_1distrprob_1_1kullbackLieblerDivergence_1_1KullbackLeiblerDivergence.html#ad35ddee427d0c39d2d50753e39a7c0e6" title="A simple getter...">get_calculated_KL_values</a>(self):
<a name="l00237"></a>00237         <span class="keywordflow">return</span> (self.kl1, self.kl2)
<a name="l00238"></a>00238 
</pre></div></div><!-- contents -->
</div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

  <div id="nav-path" class="navpath">
    <ul>
      <li class="navelem"><a class="el" href="kullbackLieblerDivergence_8py.html">kullbackLieblerDivergence.py</a>      </li>

    <li class="footer">Generated on Mon Jun 2 2014 12:15:29 for pyproct_doxy by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.6.1 </li>
   </ul>
 </div>


</body>
</html>
